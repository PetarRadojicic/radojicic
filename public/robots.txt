# https://www.robotstxt.org/robotstxt.html
User-agent: *
Allow: /

# Disallow specific file types
Disallow: /*.json$
Disallow: /*.config.js$

# Sitemap
Sitemap: https://radojicic.co/sitemap.xml

# Crawl delay (optional, helps prevent server overload)
Crawl-delay: 10

# Allow common search engines
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

User-agent: DuckDuckBot
Allow: /

User-agent: Baiduspider
Allow: /

User-agent: YandexBot
Allow: /

User-agent: facebot
Allow: /

User-agent: ia_archiver
Allow: /

